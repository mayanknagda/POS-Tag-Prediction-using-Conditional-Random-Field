{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ede5487842f6a788ae1111ea178e62f8959b9d408b1393ae932bc8013c6f2be"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# POS Tagging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              sentence  \\\n",
       "0    how long do you have to pay back debt after cl...   \n",
       "1             what shakespearean play featured shylock   \n",
       "2         which magazine is fine entertainment for men   \n",
       "3    what features of the african elephant are larg...   \n",
       "4             what ocean surrounds the maldive islands   \n",
       "..                                                 ...   \n",
       "954             what english word has the most letters   \n",
       "955  what film ends with the line this is mrs. norm...   \n",
       "956  who asked the musical question have you ever b...   \n",
       "957  who wrote poems are made by fools like me but ...   \n",
       "958                  what is a result of a dot product   \n",
       "\n",
       "                                                  tags  \n",
       "0    [WH, ADV, AUX, PART, VERB, TO, VERB, PART, NOU...  \n",
       "1                          [WH, ADJ, NOUN, VERB, NOUN]  \n",
       "2               [WH, NOUN, AUX, ADJ, NOUN, PREP, NOUN]  \n",
       "3    [WH, VERB, PREP, DT, ADJ, NOUN, AUX, ADJ, PREP...  \n",
       "4                      [WH, NOUN, VERB, DT, ADJ, NOUN]  \n",
       "..                                                 ...  \n",
       "954               [WH, ADJ, NOUN, VERB, DT, ADJ, NOUN]  \n",
       "955  [WH, NOUN, VERB, PREP, DT, NOUN, DT, AUX, ADJ,...  \n",
       "956  [WH, VERB, DT, ADJ, NOUN, VERB, PRON, VERB, VE...  \n",
       "957  [WH, VERB, NOUN, AUX, VERB, PREP, NOUN, PREP, ...  \n",
       "958           [WH, AUX, DT, NOUN, PREP, DT, ADJ, NOUN]  \n",
       "\n",
       "[959 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>how long do you have to pay back debt after cl...</td>\n      <td>[WH, ADV, AUX, PART, VERB, TO, VERB, PART, NOU...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>what shakespearean play featured shylock</td>\n      <td>[WH, ADJ, NOUN, VERB, NOUN]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>which magazine is fine entertainment for men</td>\n      <td>[WH, NOUN, AUX, ADJ, NOUN, PREP, NOUN]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what features of the african elephant are larg...</td>\n      <td>[WH, VERB, PREP, DT, ADJ, NOUN, AUX, ADJ, PREP...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>what ocean surrounds the maldive islands</td>\n      <td>[WH, NOUN, VERB, DT, ADJ, NOUN]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>954</th>\n      <td>what english word has the most letters</td>\n      <td>[WH, ADJ, NOUN, VERB, DT, ADJ, NOUN]</td>\n    </tr>\n    <tr>\n      <th>955</th>\n      <td>what film ends with the line this is mrs. norm...</td>\n      <td>[WH, NOUN, VERB, PREP, DT, NOUN, DT, AUX, ADJ,...</td>\n    </tr>\n    <tr>\n      <th>956</th>\n      <td>who asked the musical question have you ever b...</td>\n      <td>[WH, VERB, DT, ADJ, NOUN, VERB, PRON, VERB, VE...</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>who wrote poems are made by fools like me but ...</td>\n      <td>[WH, VERB, NOUN, AUX, VERB, PREP, NOUN, PREP, ...</td>\n    </tr>\n    <tr>\n      <th>958</th>\n      <td>what is a result of a dot product</td>\n      <td>[WH, AUX, DT, NOUN, PREP, DT, ADJ, NOUN]</td>\n    </tr>\n  </tbody>\n</table>\n<p>959 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "## Making Training and Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[0:int(.90*len(df))]\n",
    "test = df[int(.90*len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('how long do you have to pay back debt after claiming chapter 11 bankruptcy',\n",
       " ['WH',\n",
       "  'ADV',\n",
       "  'AUX',\n",
       "  'PART',\n",
       "  'VERB',\n",
       "  'TO',\n",
       "  'VERB',\n",
       "  'PART',\n",
       "  'NOUN',\n",
       "  'PREP',\n",
       "  'VERB',\n",
       "  'NOUN',\n",
       "  'NUMB',\n",
       "  'NOUN'])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train['sentence'][0], train['tags'][0]"
   ]
  },
  {
   "source": [
    "## Word Tag Pair / Sentence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = []\n",
    "for i in range(len(train)):\n",
    "    sentence = []\n",
    "    for j in range(len(train['sentence'][i].split(' '))):\n",
    "        d = tuple([train['sentence'][i].split(' ')[j], train['tags'][i][j]])\n",
    "        sentence.append(d)\n",
    "    train_ds.append(sentence)\n",
    "\n",
    "test_ds = []\n",
    "for i in range(len(test)):\n",
    "    sentence = []\n",
    "    for j in range(len(test['sentence'][i + len(train)].split(' '))):\n",
    "        d = tuple([test['sentence'][i + len(train)].split(' ')[j], test['tags'][i + len(train)][j]])\n",
    "        sentence.append(d)\n",
    "    test_ds.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('how', 'WH'),\n",
       "  ('long', 'ADV'),\n",
       "  ('do', 'AUX'),\n",
       "  ('you', 'PART'),\n",
       "  ('have', 'VERB'),\n",
       "  ('to', 'TO'),\n",
       "  ('pay', 'VERB'),\n",
       "  ('back', 'PART'),\n",
       "  ('debt', 'NOUN'),\n",
       "  ('after', 'PREP'),\n",
       "  ('claiming', 'VERB'),\n",
       "  ('chapter', 'NOUN'),\n",
       "  ('11', 'NUMB'),\n",
       "  ('bankruptcy', 'NOUN')],\n",
       " [('how', 'WH'),\n",
       "  ('many', 'ADJ'),\n",
       "  ('varieties', 'NOUN'),\n",
       "  ('of', 'PREP'),\n",
       "  ('apple', 'NOUN'),\n",
       "  ('are', 'AUX'),\n",
       "  ('there', 'ADV')])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_ds[0], test_ds[0]"
   ]
  },
  {
   "source": [
    "## Define Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i, m):\n",
    "    word = sent[i][0]\n",
    "    if m == 2: #with prefix and suffix\n",
    "        features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[+2:]': word[2:],\n",
    "        'word[+3:]': word[3:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    else:\n",
    "        features = { #model1 without prefix and suffixx\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent, m):\n",
    "    return [word2features(sent, i, m) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "source": [
    "## CRF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = sklearn_crfsuite.CRF(\n",
    "\n",
    "    algorithm = 'l2sgd',\n",
    "    c2 = 0.1,\n",
    "    max_iterations = 100,\n",
    "    all_possible_transitions = True\n",
    ")\n",
    "\n",
    "model2 = sklearn_crfsuite.CRF(\n",
    "\n",
    "    algorithm = 'l2sgd',\n",
    "    c2 = 0.1,\n",
    "    max_iterations = 100,\n",
    "    all_possible_transitions = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 292 ms, sys: 28.4 ms, total: 320 ms\nWall time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_m1 = [sent2features(s, m = 1) for s in train_ds]\n",
    "X_train_m2 = [sent2features(s, m = 2) for s in train_ds]\n",
    "y_train = [sent2labels(s) for s in train_ds]\n",
    "\n",
    "X_test_m1 = [sent2features(s, 1) for s in test_ds]\n",
    "X_test_m2 = [sent2features(s, 2) for s in test_ds]\n",
    "y_test = [sent2labels(s) for s in test_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/mayank/anaconda3/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CRF(algorithm='l2sgd', all_possible_transitions=True, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model1.fit(X_train_m1, y_train)\n",
    "model2.fit(X_train_m2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = list(model1.classes_)\n",
    "labels2 = list(model2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['WH',\n",
       "  'ADV',\n",
       "  'AUX',\n",
       "  'PART',\n",
       "  'VERB',\n",
       "  'TO',\n",
       "  'NOUN',\n",
       "  'PREP',\n",
       "  'NUMB',\n",
       "  'ADJ',\n",
       "  'DT',\n",
       "  'CONJ',\n",
       "  'MOD',\n",
       "  'PRON'],\n",
       " ['WH',\n",
       "  'ADV',\n",
       "  'AUX',\n",
       "  'PART',\n",
       "  'VERB',\n",
       "  'TO',\n",
       "  'NOUN',\n",
       "  'PREP',\n",
       "  'NUMB',\n",
       "  'ADJ',\n",
       "  'DT',\n",
       "  'CONJ',\n",
       "  'MOD',\n",
       "  'PRON'])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "labels1, labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8658220138927282 0.9013922444431405\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = model1.predict(X_test_m1)\n",
    "f1_1 = metrics.flat_f1_score(y_test, y_pred1,\n",
    "                      average='weighted', labels=labels1)\n",
    "\n",
    "y_pred2 = model2.predict(X_test_m2)\n",
    "f1_2 = metrics.flat_f1_score(y_test, y_pred2,\n",
    "                      average='weighted', labels=labels2)\n",
    "print(f1_1, f1_2)"
   ]
  },
  {
   "source": [
    "## Performance Matrix Model 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        PART      0.667     0.222     0.333         9\n",
      "         ADJ      0.662     0.608     0.634        74\n",
      "         ADV      0.333     0.333     0.333         3\n",
      "        VERB      0.775     0.697     0.734        89\n",
      "          WH      0.990     0.970     0.980       100\n",
      "          TO      1.000     1.000     1.000        13\n",
      "         MOD      0.800     0.571     0.667         7\n",
      "        CONJ      1.000     0.818     0.900        11\n",
      "        NOUN      0.792     0.900     0.843       250\n",
      "        PREP      0.985     0.956     0.970        68\n",
      "        PRON      0.917     0.846     0.880        13\n",
      "          DT      1.000     0.967     0.983        90\n",
      "        NUMB      1.000     0.889     0.941         9\n",
      "         AUX      1.000     1.000     1.000        78\n",
      "\n",
      "    accuracy                          0.869       814\n",
      "   macro avg      0.851     0.770     0.800       814\n",
      "weighted avg      0.869     0.869     0.866       814\n",
      "\n",
      "/home/mayank/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=['PART', 'ADJ', 'ADV', 'VERB', 'WH', 'TO', 'MOD', 'CONJ', 'NOUN', 'PREP', 'PRON', 'DT', 'NUMB', 'AUX'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "sorted_labels1 = sorted(\n",
    "    labels1,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred1, labels=sorted_labels1, digits=3\n",
    "))"
   ]
  },
  {
   "source": [
    "## Performance Matrix Model 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n        PART      0.333     0.111     0.167         9\n         ADJ      0.784     0.784     0.784        74\n         ADV      0.143     0.333     0.200         3\n        VERB      0.842     0.719     0.776        89\n          WH      0.990     0.980     0.985       100\n          TO      1.000     1.000     1.000        13\n         MOD      0.833     0.714     0.769         7\n        CONJ      1.000     1.000     1.000        11\n        NOUN      0.869     0.932     0.900       250\n        PREP      0.985     0.971     0.978        68\n        PRON      0.688     0.846     0.759        13\n          DT      1.000     0.978     0.989        90\n        NUMB      1.000     0.889     0.941         9\n         AUX      1.000     1.000     1.000        78\n\n    accuracy                          0.903       814\n   macro avg      0.819     0.804     0.803       814\nweighted avg      0.904     0.903     0.901       814\n\n"
     ]
    }
   ],
   "source": [
    "sorted_labels2 = sorted(\n",
    "    labels2,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred2, labels=sorted_labels2, digits=3\n",
    "))"
   ]
  }
 ]
}